{
  "Llama 3.2 (3B)": {
    "size": "3B",
    "num_orderings": 24,
    "min_approval": 0.6358141292028712,
    "max_approval": 0.9968698213956914,
    "range": 0.3610556921928202,
    "mean": 0.9007277715136945,
    "std": 0.1025135881053629,
    "cv": 0.11381195445221631
  },
  "Mistral (7B)": {
    "size": "7B",
    "num_orderings": 10,
    "min_approval": 0.30972222222222223,
    "max_approval": 0.9178819444444445,
    "range": 0.6081597222222223,
    "mean": 0.7104861111111112,
    "std": 0.26695147340391395,
    "cv": 0.3757307415713382
  },
  "Llama 70B (70B)": {
    "size": "70B",
    "num_orderings": 24,
    "min_approval": 0.7149305555555555,
    "max_approval": 0.9319444444444445,
    "range": 0.21701388888888895,
    "mean": 0.8310402199074073,
    "std": 0.08111054271055966,
    "cv": 0.09760122406542107
  },
  "Qwen (72B)": {
    "size": "72B",
    "num_orderings": 8,
    "min_approval": 0.7145833333333333,
    "max_approval": 0.9265625,
    "range": 0.2119791666666666,
    "mean": 0.8087878207311535,
    "std": 0.0904030252983314,
    "cv": 0.11177594788285267
  }
}